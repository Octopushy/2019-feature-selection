%%%% using 'arara' 4.0
% arara: xelatex: {synctex: yes, interaction: nonstopmode}
% arara: bibtex
% arara: xelatex: {synctex: yes, interaction: nonstopmode}
% arara: xelatex: {synctex: yes, interaction: nonstopmode}

% arara: indent: {overwrite: yes}

% arara: clean: { extensions: [aux, bcf, cod, blg, lof, lot, out, toc, log, xml, bak0 ] }

\documentclass[review]{elsarticle}

% Figures Links, mittig und rechts platzieren
\usepackage[export]{adjustbox}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}

% prevents that appendices are moved behind references
\usepackage{placeins}

\usepackage[nolist]{acronym}

\usepackage{longtable}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{float}

\graphicspath{{../03_figures/results/}{./}{../03_figures/data/}} 

% enable paragraph as 4th level https://tex.stackexchange.com/questions/60209/how-to-add-an-extra-level-of-sections-with-headings-below-subsubsection
\usepackage{titlesec}
\setcounter{secnumdepth}{4}
\titleformat{\paragraph}
{\normalfont\small\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

% enable linking to subsubsection
\setcounter{secnumdepth}{3}

% various symbols, e.g. \degree
\usepackage{gensymb}

\usepackage[hidelinks]{hyperref}

\usepackage{lineno}
\modulolinenumbers[5]

% set autoref abbr for appendix
\newcommand*{\Appendixautorefname}{appendix}

\journal{Journal "Remote Sensing of Environment"}

% line breaks in table cells
\newcommand{\specialcell}[2][l]{%
  \begin{tabular}[#1]{@{}l@{}}#2\end{tabular}}

% tilde
\newcommand{\mytilde}{\raise.17ex\hbox{$\scriptstyle\mathtt{\sim}$}}

%% APA style
\bibliographystyle{model5-names}\biboptions{authoryear}

\begin{document}

\begin{frontmatter}

	\title{Modeling defoliation of Pinus Radiata trees using hyperspectral remote sensing data}

	%% Group authors per affiliation:
	\author[FSU]{Patrick Schratz}
	\cortext[mycorrespondingauthor]{Corresponding author}
	\ead{patrick.schratz@uni-jena.de}

	\author[FSU]{Jannes Muenchow}
	\author[NEIKER]{Eugenia Iturritxa}
	%\author[TUDO]{Jakob Richter}
	\author[FSU]{Alexander Brenning}

	\address[FSU]{Department of Geography, GIScience group, Grietgasse 6, 07743, Jena, Germany}
	%\address[NEIKER]{NEIKER, Granja Modelo –Arkaute, Apdo. 46, 01080 Vitoria-Gasteiz, Arab, Spain}
	%\address[TUDO]{Department of Statistics, TU Dortmund University, Germany}

	\begin{abstract}

	\end{abstract}

	\begin{keyword}
		hyperspectral imagery \sep forest health \sep machine-learning \sep variable importance \sep model comparison
	\end{keyword}

\end{frontmatter}

\linenumbers

% längste Abkürzung steht hier!!! in eckigen Klammern
\begin{acronym}[AUROC]

	% geringerer Zeilenabstand
	%\setlength{\itemsep}{-\parsep}
	\acro{AGB}{Above-Ground Biomass}
	\acro{ANN}{Artificial Neural Network}
	\acro{AUROC}{Area Under the Receiver Operating Characteristics Curve}
	\acro{BRT}{Boosted Regression Trees}
	\acro{CART}{Classification and Regression Trees}
	\acro{CV}{cross-validation}
	\acro{ENM}{Environmental Niche Modeling}
	\acro{FPR}{False Positive Rate}
	\acro{GAM}{Generalized Additive Model}
	\acro{GBM}{Gradient Boosting Machine}
	\acro{GLM}{Generalized Linear Model}
	\acro{ICGC}{Institut Cartografic i Geologic de Catalunya}
	\acro{IQR}{Interquartile Range}
	\acro{WKNN}{Weighted $k$-nearest neighbor}
	\acro{MARS}{Multivariate Adaptive Regression Splines}
	\acro{MEM}{Maximum Entropy Model}
	\acro{NRI}{Normalized Ratio Indices}
	\acro{OLS}{Ordinary Least Squares}
	\acro{LOWESS}{Locally Weighted Scatter Plot Smoothing}
	\acro{PISR}{Potential Incoming Solar Radiation}
	\acro{RBF}{Radial Basis Function}
	\acro{RF}{Random Forest}
	\acro{RMSE}{Root Mean Square Error}
	\acro{RR}{Ridge Regression}
	\acro{RSS}{Residual Sum of Squares}
	\acro{SAR}{Synthetic Aperture Radar}
	\acro{SDM}{Species Distribution Modeling}
	\acro{SMBO}{Sequential-based Model Optimization}
	\acro{SVM}{Support Vector Machines}
	\acro{TPR}{True Positive Rate}
\end{acronym}

\section{Introduction}
\label{sec:intro}

% Explain how remote sensing is used in forestry (potential to map forest health)
Data retrieved from remote sensing satellites is successfully used in forestry to monitor temporal changes across large areas \citep{martinezdelcastilloEvaluationForestCover2015,sextonModelPropagationUncertainty2015}.
The use of \ac{SAR} techniques enables scientists to estimate \ac{AGB} \citep{luSurveyRemoteSensingbased2016, sinhaReviewRadarRemote2015}.
Forest health is commonly assesed using optical data from multi-/hyperspectral satellites by applying temporal change detections \citep{zhangRemoteSensingSeasonal2016}.
With the recent success story of machine-learning methods in the field of remote sensing, modeling techniques such as \ac{RF} are frequently used to model relationships of possible triggers to forest health \citep{belgiuRandomForestRemote2016, laryMachineLearningGeosciences2016, michezClassificationRiparianForest2016}.

With a robust model, predictions of the modelled response to large areas is possible, giving valuable information about the condition of this variable in unknown regions.
To model forest health, usually few variables are extracted based on the spectral signatures of affected and unaffected trees \citep{lelongEvaluationOilPalmFungal2010}.
However, spectral (vegetation-)indices have shown the potential to contribute valuable information to increase predictive accuracy of forest pathogens \citep{jiangSatellitederivedVegetationIndices2014, adamczykRededgeVegetationIndices2015}.

However, the amount of possible (vegetation-)indices that could be calculated is often limited due to a low spectral resolution of freely available data from optical multispectral sensors (e.g. Sentinel-2).
Also, there is currently no free data available from hyperspectral sensors that could be used for such studies (after the decommission of the EO-1 Hyperion satellite).
If the spatial resolution of the data is too coarse (e.g. $> 5 m$), the value of a pixel usually contains information from multiple trees and possibly even bare-ground information.
This makes the resulting information almost useless to be used for forest health monitoring on a tree level.

% Why are we mapping defoliation?

In this study we will use hyperspectral data with a spatial resolution of one meter and 126 spectral bands to model the health status of Monterey Pine (\textit{Pinus radiata}) plantations in northern Spain.
The trees in the study area suffer from infections of invasive pathogens such as \textit{Diplodia sapinea}, \textit{Fusarium circinatum} \textit{Armillaria mellea} or \textit{Heterobasidion annosum} leading to a spread of cankers or defoliation before the tree dies \citep{mesanzaNativeRhizobacteriaBiocontrol2016, iturritxaBiocontrolFusariumCircinatum2017}.
In-situ measurements of defoliation on a tree level are used as a proxy to model tree health.
The fungis are assumed to infect the trees through open wounds, possibly caused by previous hail damage \citep{Iturritxa2014}.
The dieback of these trees, which are mainly used as timber, causes high economic damages \citep{ganleyGlobalClimaticRisk2009}.
Hyperspectral remote sensing data in combination with state-of-the-art machine-learning techniques is used to help monitoring the health status in this region by early detecting affected trees/plots.

% Show importance of vegetation indices and NRI

To extract the most information from the available remote sensing data, we not only calculated the most common vegetation indices like \textit{NDVI} to link against defoliation but all possible ones within the spectral region of the data (400 nm - 1000 nm) that were implemented in the \textit{hsdar} package in R \citep{hsdar}.
Additionally, all possible combinations of \ac{NRI} were calculated from the data and supplied to a selection of machine-learning algorithms as predictors.


% Mention the ability of ML algs to handle highly correlated variables

Specifically the following objectives are addressed:

\begin{itemize}
	\item Comparison of multiple algorithms on their performance to model defoliation of \textit{Pinus radiata} trees using highly-correlated indices
	\item Exploration of the most important indices of the best performing model
	\item Prediction of defoliation to \textit{Pinus radiata} plots with an unknown defoliation level
\end{itemize}

\section{Data and study area}

\subsection{In-situ data}
% Describe Plots

The \textit{Pinus radiata} plots of this study, named \textit{Laukiz 1}, \textit{Laukiz 2}, \textit{Luiando} and \textit{Oiartzun}, are located in the northern part of the Basque Country (\autoref{fig:study_area}).
\textit{Oiartzun} has the most observations (n = 529) while \textit{Laukiz 2} has the largest area size (1.44 ha).
All plots besides \textit{Luiando} are located nearby the coast (\autoref{fig:study_area}).
In total 1750 observations are available (\textit{Laukiz 1} = 479, \textit{Laukiz 2} = 451, \textit{Luiando} = 291, \textit{Oiartzun} = 529).
The data was surveyed in September 2016.

\begin{figure} [t!]
	\begin{center}
		\makebox[\textwidth]{\includegraphics[width=\textwidth] {study_area_hyperspectral.pdf}}
		\caption{Information about the plot locations, the area of hyperspectral coverage and the number of trees per plot.}
		\label{fig:study_area}
	\end{center}
\end{figure}

\subsection{Hyperspectral data}

The airborne hyperspectral data was acquired during two flight campaigns on September 28th and October 5th 2016, both around 12 am.
The images were taken using a AISAEAGLE-II sensor.
All preprocessing steps (geometric, radiometric, atmospheric) have been conducted by the \ac{ICGC}.
The first four bands were corrupted, leaving 122 bands with valid information.
Additional metadata information is available in Table 1:

% parameter limits
\begin{table}[b!]
\centering
\caption[t]{Specifications of hyperspectral data.}
\begingroup\footnotesize
\begin{tabular}{ll}
	\\
	Characteristic         & Value                               \\
	\hline
	Geometric resolution   & 1 m                                 \\
	Radiometric resolution & 12 bit                              \\
	Spectral resolution    & 126 bands (404.08 nm - 996.31 nm)   \\
	Correction:            & Radiometric, geometric, atmospheric
\end{tabular}
\endgroup
\label{tab:hyperparameter_limits}
\end{table}

\section{Methods}

For all analysis steps we used the open-source statistical programming language R \citep{R_core}.
The algorithm implementations of the following packages have been used: \textit{xgboost} \citep{chenXGBoostScalableTree2016}, \textit{kernlab} \citep{kernlab} (Support Vector Machine), \cite{Vapnik1998}) and \textit{glmnet} \citep{glmnet} (Ridge Regression).
We used the R package \textit{mlr} for all modeling related steps.
It provides a standardized interface for a wide variety of statistical and machine-learning models in R simplifying essential modeling tasks such as hyperparameter tuning, model performance evaluation and parallelization \citep{bischlMlrMachineLearning2016}.

\subsection{Derivation of indices}

The idea behind calculating this amount of indices was to use the full information of the high radiometric resolution of the hyperspectral data.
Besides vegetation indices, that have been shown to be sensitive to changes to the health status of vegetation, we were interested if NRIs of arbitrary band combinations will have a substantial positive effect on the predictive power of the fitted model.
All vegetation indices (90 total) suitable for the wavelength range of the hyperspectral data that were available in the R package \textit{hsdar} have been calculated.
Additionally, all possible \ac{NRI} were calculated from the data using the formula:

\begin{equation}
	NRI_{i,j} = \frac{b_{i} - b_{j}}{b_{i} + b_{j}}
\end{equation}

\noindent
where $i$ and $j$ are the respective band numbers.

To account for geometric offsets, we used a buffer of two meters around the centroid of the respective tree.
The mean value of all pixels touched by the buffer was assigned as the final value for each index.
Missing values were removed from the mean value calculation.
In total, 7875 Normalized Ratio Indices NRI have been calculated ($\frac{125*126}{2}$).
Due to four corrupted bands and some other numerical problems, few indices returned \texttt{NA} values for some observations.
These indices were removed from the dataset, leaving a total of 7471 variables without missing values.

\subsection{Benchmarking of algorithms}

Multiple algorithms were benchmarked on predictive performance to find the best performing one.
Besides the well-known \ac{SVM} \citep{Vapnik1998} we also used \textit{xgboost} which is ensemble method relying on the idea of tree boosting that gained a lot of attention in recent years \citep{chenXGBoostScalableTree2016}.
We also added penalized L2 (Ridge) regression to the algorithm collection due to its ability to handle highly correlated covariates.
The probably most popular machine-learning algorithm, Random Forest, was not considered for this study: Due to the high number of variables, model fitting times in the range hours for a single model fit were not practicable for this work.
These high fitting times are caused by hyperparameter \texttt{mtry} which scales with the number of variables \citep{Probst2018b}.
After the selection of the best model, we checked if the winning algorithm can achieve a similar performance when using only the most important variables compared to using all variables.
We did not use a robust selection metric here but just selected the \texttt{n} most important variables by inspecting the importance score of the model (\autoref{fig:var-imp}).

% \subsubsection{The ridge penalty}

% In \ac{RR} (also called $\ell_{2}$ penalization) the assumption of unbiased coefficients is given up in favor of higher predictive accuracy and reduced variance \citep{Hastie2001}.
% Coefficients are standardized and penalized for their size.
% When minimizing the \ac{RSS}, \ac{RR} adds a penalization term $\lambda \sum_{j=1}^{p}\beta_{j}^{2}$ to the equation:

% \begin{equation}
% 	RSS = \sum_{i=1}^{n} \left(y_{i} - \beta_{0} - \sum_{j=1}^{p} \beta_{j} x_{ij} \right) ^{2} + \lambda \sum_{j=1}^{p}\beta_{j}^{2}
% \end{equation}

% where $\lambda >= 0$ is a tuning parameter responsible for the magnitude of penalization.
% To make the second term (usually referred to as the \textit{shrinkage penalty}) of this equation small, the coefficients $\beta_{j}$ need to become small.
% Unlike to Lasso however, predictors are not removed from the final model and will always be $\beta_{j} >= 0$.
% Hence, $\lambda$ has the effect of shrinking the coefficients when minimizing the \ac{RSS}.
% For $\lambda = 0$, no penalization is done and standard \ac{OLS} applies \citep{James2013}.
% The \textit{shrinkage penalty} is only applied to the coefficients and not to the intercept.
% Also, while \ac{OLS} generates only one set of coefficient estimates, \ac{RR} will create multiple sets for every value of $\lambda$.
% In summary, the advantage of \ac{RR} is based on the bias-variance tradeoff: For $\lambda\to\infty$, the flexibility of the fit is reduced leading to a decrease in variance of the coefficients but also introduces a (substantial) bias.
% For $\lambda = 0$, the variance is high but coefficients are unbiased \citep{James2013}.

\subsubsection{Performance estimation}

The algorithms were benchmarked in two ways:
(1) Using spatial \ac{CV} for each plot using on the k-means clustering approach of \cite{Brenning2012}. To reduce runtime we used a five-fold five-times repeated CV setup.
(2) Using spatial \ac{CV} on the plot level with each plot being the test set once. This results in four performance estimates, one for each fold.
For (1) we only used the best performing algorithm from (2).
The reason why the (2) was chosen for algorithm selection is that this model will also be used to spatially predict defoliation in other plots.

% Add figure visualizing both spCV approaches

\subsubsection{Hyperparameter tuning}
To tune the hyperparameters of the algorithms, we used \ac{SMBO} via the R package \textit{mlrMBO} \citep{mlrMBO}.
This Bayesian approach first composes \textit{n} randomly chosen hyperparameter settings out of a user defined search space.
After these \textit{n} tries have been evaluated, a new hyperparameter setting to be evaluated next is proposed based on the setting that performed best.
This strategy continues until a termination criterion, defined by the user, is reached \citep{Hutter2011, Jones1998}.
In this work we used an initial design of 30 randomly composed hyperparameter settings and a termination criterion of 20 iterations, resulting a total budget of 50 evaluated hyperparameter settings per fold.
The advantage of this tuning approach is that it substantially reduces the tuning budget which is needed to find a setting close to the global minimum compared to methods that do not use information from previous runs such as \textit{random search} or \textit{grid search} \citep{Bergstra2012}.

\subsection{Variable importance}

To find indices that contributed most to model performance, we used the internal variable importance measure of the \textit{xgboost} algorithm.
The score is calculated by taking the contribution of each feature for each tree in the fitted model.
The higher the score of a variable, the more important it is for the fitted model when making predictions \citep{chenXGBoostScalableTree2016}.
Using the internal variable importance measure from the xgboost algorithm is quite convienient since it is automatically computed during model fit.
By contrast to other approaches such as permutation-based variable importance, it is composed out of three parts that contribute to the overall importance score:

\begin{itemize}
	\item Gain: The relative contribution of the feature to the model
	\item Cover metric: How often a feature was selected to be the deciding feature in a tree for a specific observation
	\item Frequency How often a feature occurs in all trees of the model
\end{itemize}

The \textit{Gain} features is the most important one among the three.
All measures sum up to one (REFERENCE!).

% partial dependence plots??

\section{Results}

\subsection{Plot characteristics}

% defoliation boxplots
\begin{figure} [t!]
	\begin{center}
		\makebox[\textwidth]{\includegraphics[width=0.7\textwidth] {boxplot_defol.pdf}}
		\caption{Descriptive statistics of the response variable \textit{defoliation}.}
		\label{fig:defol_boxplots}
	\end{center}
\end{figure}

\textit{Oiartzun} shows the highest defoliation ($\bar{x} = 69.22 \%$) among the plots while \textit{Laukiz 2} is the healthiest ($\bar{x} = 13.54 \%$) (\autoref{fig:defol_boxplots}).
All plots besides \textit{Luiando} show an evenly distributed level of defoliation across the entire plot.

The high degree of defoliation of \textit{Luiando} and \textit{Oiartzun} is also visible in the spectral signatures of the plots (\autoref{fig:spectral_signatures}).
Both plots show lower mean reflectance values around the wavelength range 800 nm - 1000 nm compared to Laukiz 1 and Laukiz 2.
Oiartzun is almost completely missing the reflectance drop at around 815 nm that is visible for all other plots but instead shows a higher magnitude for the reflectance increase at around 920 nm.
Laukiz 2 shows a mean tree density of 61.59 m \autoref{fig:rmse_defol_dens}) while all other plots are more dense (34.64 (Laukiz 1), 33.01 (Luiando), 34.96 (Oiartzun)) (\autoref{fig:plot-characteristics}).

\subsection{Predictive performance}

% Performance estimates
\begin{table}[t!]
\centering
\caption[t]{Four-fold block spatial \ac{CV} performances of RR, SVM and xgboost using \ac{RMSE} as the error measure.
	Mean and standard deviation are shown.}
\begingroup\footnotesize
\begin{tabular}{llll}
	RR            & SVM           & xgboost       & xgboost (7 variables) \\
	\hline
	59.10 (22.71) & 36.23 (15.73) & 33.26 (16.61) &                       \\
	\bottomrule
\end{tabular}
\endgroup
\label{tab:model_comparison}
\end{table}

\begin{table}[t!]
\centering
\caption[t]{Predictive performance of \textit{xgboost} using all observations (All Observations) and observations from specific plots only (Single Plot Observations) with \ac{RMSE} as the error measure. The performance estimates for "All Observations" correspond to the fold for which the respective plot was serving as the test set. Column "Single Plot Observations", shows the mean performances at the repetition level of a spatial CV (5 folds, 5 repetitions), scored by using data of the respective plot only.}
\begingroup\footnotesize
\begin{tabular}{llll}
	\\
	Plot/Data & \specialcell{All Observations/ \\{all variables (Block CV)}} & \specialcell{All Observations/         \\ {7 variables (Block CV)}} & \specialcell{Plot level observations/\\{all variables (SpCV)}} \\
	\hline
	Laukiz 1  & 22.03                                                                              & 21.47                          & 19.18 \\
	Laukiz 2  & 51.75                                                                              & 49.94                          & 17.24 \\
	Luiando   & 13.20                                                                              & 15.37                          & 8.30  \\
	Oiartzun  & 32.97                                                                              & 17.62                          & 14.40 \\
	\bottomrule
\end{tabular}
\endgroup
\label{tab:supermodel_performance}
\end{table}

\subsubsection{Algorithm benchmarking}

The \textit{xgboost} algorithm shows the lowest error (33.26 RMSE) when benchmarking the learners on the complete dataset of all plots (\autoref{tab:model_comparison}).
While the SVM performance is only slightly worse (36.23 RMSE), RR shows a large drop in performance compared to xgboost (59.10 RMSE).

\subsubsection{Single models vs. super model}

When comparing the mean predictive performance of models fitted at the plot level against the performance of the model that was fitted using all data, the plot-level models show a better performance in all cases (\autoref{tab:supermodel_performance}).
The highest difference between both models types occurs for \textit{Laukiz2} with a difference of 34.51 RMSE.

Using only the seven most important variables (\autoref{fig:var-imp}) for the super model shows small increases in performance for Laukiz 1 and Laukiz 2, a small decrease for Luiando and almost a reduction of 50\% of the error for Oiartzun (32.97 vs. 17.62 RMSE) (\autoref{tab:supermodel_performance}).

\subsubsection{RMSE vs. plot characteristics}

\noindent An increase of the error rate was observed with an increase of descriptive plot measures such as mean point density and the coefficient of variation (based on the response \textit{defoliation}) (\autoref{fig:plot-characteristics}).

\begin{figure} [b!]
	\begin{center}
		\makebox[\textwidth]{\includegraphics[width=\textwidth] {plot-characteristics.pdf}}
		\caption{RMSE vs. mean point density and coefficient of variation (defoliation).}
		\label{fig:plot-characteristics}
	\end{center}
\end{figure}

\subsection{Variable importance}

\noindent The seven most important features of the super model in this study were vegetation indices with \textit{EVI} \citep{hueteComparisonVegetationIndices1997} being the most important one (\autoref{fig:var-imp}).

\begin{equation}
	EVI = 2.5*\frac{R_{800}-R_{670}}{R_{800}-(6*R_{670})-(7.5*R_{475})+1)}
\end{equation}

\noindent where $R$ = Reflectance at the respective wavelength.

\bigbreak

\noindent Vegetation index \textit{GDVI} appears three times among the first seven most important features (\autoref{fig:var-imp}) with different \texttt{n} values.
This is because it was computed four times, with \texttt{n} ranging from 1 - 4 \citep{wuEstimatingChlorophyllContent2008}:

\begin{equation}
	GDVI = \frac{R_{800}^n-R_{680}^n}{R_{800}^n+R_{680}^n}
\end{equation}

\bigbreak

\noindent The seven most important features (\textit{EVI}, \textit{GDVI4}, \textit{D1}, \textit{GDVI3}, \textit{GDVI2}, \textit{mNDVI} and \textit{mSR}) show a substantial difference compared to all following variables (\autoref{fig:var-imp}).

\begin{figure} [b!]
	\begin{center}
		\makebox[\textwidth]{\includegraphics[width = 1\textwidth] {var-imp-xgboost.pdf}}
		\caption{The 30 most important variables as estimated by the internal variable importance measure of the \textit{xgboost} algorithm. The higher the score, the more important the feature.
			"bf2" means that a buffer of 2 meter was used to extract the variable information to the tree observation. "NRI" means that a normalized ratio index with the subsequent bands was calculated. Features without "NRI" prefix are vegetation indices, e.g. "bf2\_EVI".}. %An overview of the vegetation indices can be found \href{https://rdrr.io/cran/hsdar/man/vegindex.html}{here}.}
		\label{fig:var-imp}
	\end{center}
\end{figure}

\begin{table}[t!]
\centering
\caption[t]{Formulas of the five most important vegetation indices of the super model. $R$ = Reflectance at wavelength, $D$ = First derivation of reflectance value at wavelength.}
\begingroup\footnotesize
\begin{tabular}{llll}
	\\
	Acronym & Name                      & Formula                                                            & Reference                                                 \\
	\hline
	EVI     & Enhanced vegetation index & $2.5*\frac{R_{800}-R_{670}}{R_{800}-(6*R_{670})-(7.5*R_{475})+1)}$ & \cite{hueteComparisonVegetationIndices1997}               \\
	GDVI    & Generalized DVI*          & $\frac{R_{800}^n-R_{680}^n}{R_{800}^n+R_{680}^n}$                  & \cite{wuEstimatingChlorophyllContent2008}                 \\
	D1      & Derivative Index          & $\frac{D_{730}}{D_{706}}$                                          & \cite{zarco-tejadaSteadystateChlorophyllFluorescence2003} \\
	mNDVI   & Normalized DVI*           & $  \frac{R_{800}-R_{680}}{(R_{800}+R_{680}-2*R_{445}}$             & \cite{simsRelationshipsLeafPigment2002}                   \\
	mSR     & Simple Ratio Index        & $\frac{R_{800}-R_{445}}{R_{680}-R_{445}}$                          & \cite{simsRelationshipsLeafPigment2002}                   \\
	\bottomrule
	\multicolumn{2}{l}{\small{* Difference Vegetation Index}}
\end{tabular}
\endgroup
\label{tab:most_imp_vars}
\end{table}

The best NRI scored rank eight (band 112 and band 62).
All further places up to rank 30 are NRIs.

\subsection{Spatial prediction}




\section{Discussion}

\subsection{Derivation of indices}

The buffer of 2m that we used to generate the index value for each observation can be seen critical.
When using now buffer at all, the possibility exists that a pixel value is assigned to the tree observation that does not spatially match with the tree observation.
Using a buffer of more than 2 meters would cause information from other trees to be merged into the pixel value, blurring the actual value of the tree observation.
Thats why using a buffer of 2m was the best compromise here in our perspective.

The exact number of contributing pixels to the final index value of an observation cannot be determined as it depends on the location of the tree within the pixel grid.
As the buffer is a circle, it depends on the exact location of a tree observation within a pixel how much surrounding pixels will be used to calculate the final pixel value.
If a tree observation is located at the border of the plot, some directions of the buffer will not contain image values and the subsequent index value will be calculated using less pixels than if the tree observation is located in the middle of the plot.

Using a buffer in the first place and the fact that it is unclear how much information from other trees went into the calculation of an index value of a certain observation certainly limits the meaningfullness of the study and has to be considered when making interpretations about the outcome of this study.

\subsection{RMSE vs. plot characteristics}

Trying to relate the modeling error to plot characteristics (mean point density, CV) did not show a clear picture: For both comparisons, Laukiz 2 did not follow the pattern that was observed from the other three plots (\autoref{fig:plot-characteristics}) of having an increase in error with an increase in mean point density and CV.

Having an increase in error with an increase in mean point density could be related to the buffer we used in this study.
If a tree is surrounded by bare ground, chances are higher that bare ground information will be included in the final index value.
By contrast, if the density of trees in a plot is high, the possibility of bare ground information in the calculated index value will be small.
The fact of having information from another tree in the final pixel value is less problematic than having bare ground information as the latter affects the final index calculation more in a negative way.

Nevertheless, it has to be considered that we only had four plots in this work.
To make a valid statement about a relationship between modeling error and these plot characteristics, a larger sample size of plots is needed.

\subsection{Predictive Performance}

\subsubsection{Algorithm benchmarking}

The relatively large difference in performance between RR (59.10 RMSE) and the machine-learning models (36.23 and 33.26 RMSE) is surprising.
RR has shown promising performance results in other studies when many highly-correlated predictors were involved (REFERECES).
However, in this study, RR was not able to achieve a sufficient performance score compared to SVM and xgboost even though its hyperparameter $\lambda$ was properly tuned using SMBO.

While xgboost shows a slightly better performance than SVM, the latter has the advantage of only having two hyperparameters that need to be tuned.
This results in a shorter runtime.
Nevertheless, xgboost showed the best performance and was subsequently used to fit the models on the plot level and for the prediction.

An important point that needs to be considered when interpreting the performance results is that we only related defoliation to indices derived from remote sensing data.
Possible other cofounding factors that could possibly help in predicting defoliation were not considered.
One example here is tree age: The older a tree the more vulnerable it may be to pathogen infections causing defoliation.
However, such predictors would not be available for a spatial prediction scenario and one of the main goals of this study is to relate defoliation to variables that are available on a larger scale (e.g. remote sensing indices).

\subsubsection{Single models vs. super model}

It is expected that models that were trained on the plot level only achieve a better performance than the global model.
The low performance on Laukiz 2 for the super model is most likely due to the difference of this plot to all others: The fitted model on Laukiz 1, Luiando and Oiartzun is not capable of reaching a good performance on the Laukiz 2 prediction data.
This is not surprising as Laukiz 2 shows substantially different plot characteristics compared to all others plots in terms of the distribution of the response variable \textit{defoliation} (\autoref{fig:defol_boxplots}) and the mean point density of trees (\autoref{fig:plot-characteristics}).

The low error for Luiando (8.30 RMSE) for the plot model validates the approach of relating defoliation to vegetation indices and NRI.
The overall error of the super model (33.26 RSME) is expected to decrease if more plots are available for training.
To reach an optimal performance, the fitted model would need to include at least one instance of every plot that shows unique characteristics (i.e. here Laukiz 2 is substantially different to the others).
Possibly more plots showing unique characteristics exists that are not integrated into the fitted model of this work.

An interesting find is that the supermodel with only seven variables shows a better overall performance than the model with all 7471 variables (\autoref{tab:supermodel_performance}).
This leads to the conclusion that adding as many variables as possible to a model will not necessarily improve its performance.
In contrast, too much information can even be problematic for the model as it will have a hard time prioritizing variables.
However, to find the most important variables in the first place and to check for the performance difference, a model with all variables needs to fitted first.
This scenario cannot be generalized and different results may occur for other datasets.
Using a model with only a few predictors does not only simplify prediction tasks but also reduces runtime for hyperparameter tuning and performance estimation.

\subsection{Variable importance}

There are some downsides using the internal variable importance approach of xgboost: Due to the contribution of three different parts to the overall importance score it is complicated to understand why a specific feature was selected.
Furthermore the importance calculation approach is only valid for this algorithm and cannot be compared to others.
Nevertheless, as we only relied on the variable importance for this specific algorithm, using the internal xgboost approach was sufficient for this work.

It is not surprising that vegetation indices are most important for the model as they are most sensitive to changes in vegetation health.
Even though we are not directly looking at vegetation health but using the level of defoliation as a proxy, these indices seem to help the model most deciding whether a tree is defoliated or not.
Vegetation indices can help here in two ways:
1) Trees that show a high level of defoliation do also reflect their bad health status through the remaining foliation.
2) Defoliated trees have more influence of bare ground information in their pixel values and will therefore be classified as defoliated by the model.

Even though no NRI made it among the most important variables in this study (stating that the first seven of this study are the most important ones), it is interesting that all ranks from 8 - 30 are occupied by NRI (\autoref{fig:var-imp}).

Our statement saying that the important indices of this study are the first seven can be seen critical as we only based the selection on a visual inspection of the variable importance results (\autoref{fig:var-imp}).
The decision to make a cut between rank seven and eight was based on a combination of two facts: 1) Using only vegetation indices is easier for large scale predictions using satellites like Sentinel-2 (most NRI cannot be used with it) and 2) the drop in the importance score of the variable importance results (\autoref{fig:var-imp}).
However, based on this statement, we could also have made the cut between rank five and 6 but including the two vegetation indices at rank six and seven will eventually improve the model and does not increase runtime.

\section{Conclusion}

\section{Appendix}

\appendix
% https://tex.stackexchange.com/questions/248704/cross-reference-to-appendix-sections-in-elsarticle-document-class
\gdef\thesection{\Alph{section}} % corrected redefinition of "\thesection"
\makeatletter
\renewcommand\@seccntformat[1]{Appendix \csname the#1\endcsname.\hspace{0.5em}}
\makeatother

\section{Spectral signatures of each plot}

% spectral signatures
\begin{figure} [H]
	\begin{center}
		\makebox[\textwidth]{\includegraphics[width=\textwidth] {spectral_signatures.pdf}}
		\caption{Spectral signatures (mean and standard deviation) of each plot.}
		\label{fig:spectral_signatures}
	\end{center}
\end{figure}

\pagebreak

\section*{References}

\bibliography{Biblio_hyperspectral}

\end{document}
